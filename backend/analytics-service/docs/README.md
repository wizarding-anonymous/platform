# Спецификация Микросервиса: Analytics Service

**Версия:** 1.0
**Дата последнего обновления:** 2023-10-28

## 1. Обзор Сервиса (Overview)

### 1.1. Назначение и Роль
*   Analytics Service является центральным компонентом платформы "Российский Аналог Steam", ответственным за сбор, обработку, анализ и предоставление данных и инсайтов, генерируемых на платформе.
*   Его основная роль - поддержка принятия решений на основе данных для бизнес-стратегии, операционных улучшений, улучшения пользовательского опыта, а также предоставление разработчикам релевантной статистики по их продуктам.
*   Основные бизнес-задачи: сбор и обработка данных, расчет метрик и KPI, генерация отчетов, анализ поведения пользователей, сегментация аудитории, поддержка предиктивной аналитики.

### 1.2. Ключевые Функциональности
*   **Сбор данных:** Прием событий и данных от всех микросервисов (действия пользователей, транзакции, системные логи, маркетинговые взаимодействия). Поддержка потоковой и пакетной загрузки.
*   **Обработка данных:** Потоковая и пакетная обработка сырых данных (трансформация, агрегация, очистка, анонимизация PII в соответствии с 152-ФЗ).
*   **Метрики и Отчетность:** Расчет KPI и метрик (DAU, MAU, ARPU, конверсии, удержание). Генерация стандартных и настраиваемых отчетов.
*   **Анализ поведения пользователей:** Инструменты для анализа путей пользователей, когортного анализа, результатов A/B тестов.
*   **Сегментация аудитории:** Создание статических и динамических сегментов пользователей.
*   **Предиктивная аналитика:** Разработка и развертывание ML моделей (прогнозирование продаж, оттока, рекомендации, обнаружение мошенничества).
*   **Мониторинг производительности системы:** Агрегация и анализ метрик здоровья и производительности микросервисов платформы.

### 1.3. Основные Технологии
*   **Языки обработки данных:** Scala, Python, Java (согласно `project_technology_stack.md`).
*   **Языки API слоя:** Go, Java (согласно `project_technology_stack.md`).
*   **Фреймворки обработки данных:** Apache Spark (batch), Kafka Streams или Apache Flink (stream).
*   **Хранилища данных:**
    *   Аналитическая СУБД: ClickHouse.
    *   Data Lake / Сырые данные: S3-совместимое хранилище (например, MinIO).
    *   Метаданные и конфигурация: PostgreSQL.
*   **Брокер сообщений / Потоковая обработка событий:** Apache Kafka.
*   **Машинное обучение:** TensorFlow, PyTorch, Scikit-learn, MLflow.
*   **Типы API:** REST (Spring Boot для Java, Echo/Gin для Go), GraphQL (Apollo Server, Hasura).
*   **Визуализация данных:** Grafana, Apache Superset.
*   (Ссылки на `project_technology_stack.md`, `project_glossary.md`)

### 1.4. Термины и Определения (Glossary)
*   См. `project_glossary.md`.
*   **Событие (Event):** Запись о действии пользователя или системы.
*   **KPI (Key Performance Indicator):** Ключевой показатель эффективности.
*   **Сегмент (Segment):** Группа пользователей с общими характеристиками.
*   **ML Модель (Machine Learning Model):** Модель для предиктивной аналитики.

## 2. Внутренняя Архитектура (Internal Architecture)

### 2.1. Общее Описание
*   Analytics Service использует архитектуру, оптимизированную для обработки больших данных (Big Data) и машинного обучения. Вероятно, это будет комбинация Lambda/Kappa архитектуры.
*   Ключевые компоненты: Сбор данных (Data Ingestion), Обработка данных (Data Processing - batch/stream), Хранение данных (Data Storage - DWH, Data Lake), API доступа к данным (Data Access API), Слой ML моделей.
*   [Диаграмма архитектуры Analytics Service, показывающая потоки данных и компоненты, будет добавлена в будущих версиях документации.]

### 2.2. Слои Сервиса / Компоненты

#### 2.2.1. Data Ingestion Layer (Слой Приема Данных)
*   Ответственность: Прием событий из Kafka от всех микросервисов платформы. Валидация схем событий (базовая). Сохранение сырых данных в Data Lake (S3).
*   Ключевые компоненты/модули: Kafka Consumers, коннекторы к S3.

#### 2.2.2. Data Processing Layer (Слой Обработки Данных)
*   Ответственность: Трансформация, агрегация, обогащение, очистка данных. Расчет метрик.
*   Ключевые компоненты/модули:
    *   Stream Processing Engine (Kafka Streams/Flink): Для обработки данных в реальном времени и расчета real-time метрик.
    *   Batch Processing Engine (Spark): Для сложных пакетных расчетов, ETL процессов, подготовки данных для ML.
    *   Загрузка обработанных данных в DWH (ClickHouse).

#### 2.2.3. Data Storage Layer (Слой Хранения Данных)
*   Ответственность: Хранение сырых, обработанных данных и метаданных.
*   Ключевые компоненты/модули:
    *   Data Lake (S3): Хранение всех сырых событий.
    *   Data Warehouse (ClickHouse): Хранение агрегированных данных, витрин данных, метрик для быстрого анализа.
    *   Metadata Store (PostgreSQL): Хранение схем данных, конфигураций пайплайнов, определений отчетов, метаданных ML моделей.

#### 2.2.4. Data Access & API Layer (Слой Доступа к Данным и API)
*   Ответственность: Предоставление доступа к данным и результатам анализа через API.
*   Ключевые компоненты/модули:
    *   REST API (Go/Java): Для запроса метрик, отчетов, сегментов.
    *   GraphQL API: Для гибких запросов к данным.
    *   WebSocket API: Для стриминга real-time метрик.

#### 2.2.5. Machine Learning Layer (Слой Машинного Обучения)
*   Ответственность: Тренировка, развертывание и обслуживание ML моделей. Предоставление API для получения прогнозов.
*   Ключевые компоненты/модули: MLflow (управление моделями), TensorFlow/PyTorch/Scikit-learn (библиотеки), API для прогнозов.

## 3. API Endpoints

### 3.1. REST API
*   **Базовый URL (через API Gateway):** `/api/v1/analytics`
*   **Аутентификация:** JWT (для доступа администраторов/разработчиков к статистике), возможно API ключи для межсервисного доступа к определенным данным.
*   **Авторизация:** На основе ролей (например, `admin` для общей статистики, `developer` для статистики по своим играм).
*   (Общие принципы см. `project_api_standards.md`)

#### 3.1.1. Ресурс: Метрики (Metrics)
*   **`GET /metrics`**
    *   Описание: Получение списка доступных метрик и их описаний.
    *   Требуемые права доступа: `admin`, `developer`.
*   **`GET /metrics/{metric_name}`**
    *   Описание: Получение данных по конкретной метрике.
    *   Query параметры: `time_range_start`, `time_range_end`, `dimensions` (например, `game_id`, `country`), `filters`, `granularity` (например, `daily`, `monthly`).
    *   Пример ответа: `{ "data": { "metric_name": "dau", "values": [ {"date": "2023-10-01", "value": 1000}, ... ] } }`
    *   Требуемые права доступа: `admin`, `developer` (с ограничениями по доступу к данным).
*   **`GET /metrics/realtime`**
    *   Описание: Получение real-time агрегированных метрик (например, текущее количество активных пользователей).
    *   Требуемые права доступа: `admin`.

#### 3.1.2. Ресурс: Отчеты (Reports)
*   **`GET /reports`**
    *   Описание: Получение списка доступных стандартных и кастомных отчетов.
    *   Требуемые права доступа: `admin`, `developer`.
*   **`POST /reports/{report_id}/generate`**
    *   Описание: Запуск генерации отчета (асинхронная операция).
    *   Тело запроса: Параметры для отчета (например, период, фильтры).
    *   Требуемые права доступа: `admin`, `developer`.
*   **`GET /reports/instances/{instance_id}`**
    *   Описание: Получение статуса генерации отчета.
    *   Требуемые права доступа: `admin`, `developer`.
*   **`GET /reports/instances/{instance_id}/download`**
    *   Описание: Загрузка сгенерированного отчета (например, в CSV, PDF).
    *   Требуемые права доступа: `admin`, `developer`.

#### 3.1.3. Ресурс: Сегменты (Segments)
*   **`GET /segments`**
    *   Описание: Получение списка пользовательских сегментов.
    *   Требуемые права доступа: `admin`, `marketing_specialist`.
*   **`POST /segments`**
    *   Описание: Создание нового пользовательского сегмента на основе критериев.
    *   Тело запроса: Определение критериев сегмента.
    *   Требуемые права доступа: `admin`, `marketing_specialist`.
*   **`GET /segments/{segment_id}/users`**
    *   Описание: Получение списка пользователей в сегменте (или их количества).
    *   Требуемые права доступа: `admin`, `marketing_specialist`.
*   **`POST /segments/{segment_id}/export`**
    *   Описание: Экспорт пользователей сегмента (например, для маркетинговых кампаний).
    *   Требуемые права доступа: `admin`, `marketing_specialist`.

#### 3.1.4. Ресурс: Предиктивная Аналитика (Predictions)
*   **`GET /predictions/models`**
    *   Описание: Получение списка доступных ML моделей и их описаний.
    *   Требуемые права доступа: `admin`.
*   **`POST /predictions/{model_name}/predict`**
    *   Описание: Запрос прогноза от конкретной ML модели.
    *   Тело запроса: Входные данные для модели.
    *   Пример ответа: `{ "data": { "prediction_type": "churn_probability", "user_id": "...", "probability": 0.75 } }`
    *   Требуемые права доступа: `admin` или специфические сервисные роли.

### 3.2. GraphQL API
*   **Эндпоинт:** `/api/v1/analytics/graphql`
*   Описание: Предоставляет гибкий язык запросов для клиентов для получения кастомных наборов данных, метрик и конфигураций отчетов. Позволяет получать сложные вложенные данные за один запрос.
*   [Схема GraphQL, включая основные типы Query, Mutation, Subscription, будет определена и добавлена в последующих версиях, если будет принято решение об использовании GraphQL.]

### 3.3. WebSocket API (для стриминга метрик)
*   **Эндпоинт:** `/api/v1/analytics/ws/streaming`
*   Описание: Используется для подписки на потоки данных в реальном времени, такие как обновления real-time метрик или системные алерты.
*   [Протокол сообщений WebSocket для стриминга метрик будет определен и добавлен в последующих версиях, если будет принято решение об использовании WebSocket для этих целей.]

## 4. Модели Данных (Data Models)

### 4.1. Основные Сущности/Структуры Данных
*   **Event (Событие):**
    *   Типичная структура события соответствует CloudEvents (см. `project_api_standards.md`).
    *   Хранятся в Data Lake (S3) в сыром виде (например, JSON или Avro).
    *   Агрегированные и обработанные события хранятся в ClickHouse.
*   **Metric (Метрика):**
    *   Определения метрик (имя, описание, формула расчета, измерения, гранулярность) хранятся в PostgreSQL.
    *   Значения метрик хранятся в ClickHouse.
    *   Пример структуры таблицы для метрик в ClickHouse:
        ```sql
        CREATE TABLE metrics_daily (
            date Date,
            metric_name String,
            dimensions Map(String, String), -- Например, {'game_id': 'uuid', 'country': 'RU'}
            value Float64
        ) ENGINE = MergeTree() PARTITION BY toYYYYMM(date) ORDER BY (metric_name, date, dimensions);
        ```
*   **ReportDefinition / ReportInstance (Отчет):**
    *   Определения отчетов (имя, параметры, SQL-запрос к ClickHouse или логика генерации) хранятся в PostgreSQL.
    *   Сгенерированные экземпляры отчетов (метаданные в PostgreSQL, файлы в S3).
*   **SegmentDefinition (Сегмент):**
    *   Определения сегментов (имя, критерии фильтрации пользователей) хранятся в PostgreSQL.
*   **MLModelMetadata (ML Модель):**
    *   Метаданные ML моделей (имя, версия, параметры, метрики качества) хранятся в PostgreSQL или MLflow. Артефакты моделей в S3/MLflow.
*   [Детальные схемы для PostgreSQL и ClickHouse для каждой сущности будут предоставлены в отдельных документах по моделям данных или в будущих обновлениях этой спецификации.]

### 4.2. Схема Базы Данных
*   **ClickHouse:** Основное хранилище для аналитических запросов, агрегированных данных, витрин.
*   **PostgreSQL:** Хранение метаданных: определения метрик, отчетов, сегментов, конфигурации ML моделей, статусы задач обработки.
*   **S3 (Data Lake):** Хранение сырых событий, артефактов ML моделей, больших отчетов.
*   [Mermaid ERD для PostgreSQL и основные DDL для ClickHouse и PostgreSQL будут добавлены в будущих версиях документации или в отдельных документах по проектированию баз данных.]

## 5. Потоковая Обработка Событий (Event Streaming)

### 5.1. Публикуемые События (Produced Events)
*   Analytics Service в основном является потребителем событий. Однако он может публиковать:
*   **`analytics.report.generated.v1`**
    *   Описание: Отчет сгенерирован и доступен.
    *   Топик: `analytics.events`
    *   Структура Payload: `{ "report_instance_id": "...", "report_name": "...", "status": "success", "download_url": "...", "generated_at": "..." }`
    *   Потребители: Notification Service (уведомить пользователя), Developer Service (если отчет для разработчика).
*   **`analytics.segment.updated.v1`**
    *   Описание: Пользовательский сегмент обновлен (например, пересчитан состав).
    *   Топик: `analytics.events`
    *   Структура Payload: `{ "segment_id": "...", "user_count": 12345, "updated_at": "..." }`
    *   Потребители: Marketing tools, Notification Service (для кампаний).
*   **`analytics.alert.triggered.v1`**
    *   Описание: Сработал аналитический алерт (например, резкое падение DAU).
    *   Топик: `analytics.alerts`
    *   Структура Payload: `{ "alert_name": "DAU_drop", "severity": "critical", "details": {...}, "timestamp": "..." }`
    *   Потребители: Admin Service, Notification Service (для оповещения администраторов).

### 5.2. Потребляемые События (Consumed Events)
*   Analytics Service является основным потребителем событий от **всех** других микросервисов платформы.
*   **Топики:** `account.events`, `auth.events`, `catalog.events`, `library.events`, `payment.events`, `download.events`, `social.events`, `notification.events`, `developer.events`, `admin.events`.
*   **Формат событий:** CloudEvents JSON (согласно `project_api_standards.md`).
*   **Логика обработки:**
    *   Валидация схемы события.
    *   Сохранение сырого события в Data Lake (S3).
    *   Потоковая обработка (Kafka Streams/Flink) для:
        *   Обогащения данных (например, добавление геолокации по IP).
        *   Расчета real-time метрик.
        *   Обновления пользовательских профилей для аналитики.
        *   Обнаружения паттернов / аномалий.
    *   Пакетная обработка (Spark) для:
        *   ETL в DWH (ClickHouse).
        *   Пересчета сложных метрик и KPI.
        *   Тренировки ML моделей.
        *   Генерации отчетов.

## 6. Интеграции (Integrations)

### 6.1. Внутренние Микросервисы
*   **Все микросервисы (через Kafka):** Основной источник данных для Analytics Service.
*   **Developer Service:** Предоставление аналитики и отчетов по играм для разработчиков (через API Analytics Service).
*   **Admin Service:** Предоставление общеплатформенных дашбордов и отчетов для администраторов (через API Analytics Service).
*   **Catalog Service / Recommendation Service (потенциально):** Может получать обработанные данные (например, метрики популярности, пользовательские предпочтения) для улучшения рекомендаций или ранжирования контента.
*   **Notification Service:** Для отправки уведомлений о готовности отчетов или срабатывании алертов.
*   **Auth Service:** Для аутентификации и авторизации запросов к API Analytics Service.

### 6.2. Внешние Системы
*   **S3-совместимое хранилище:** Для Data Lake и хранения артефактов.
*   **Внешние маркетинговые инструменты (потенциально):** Экспорт сегментов пользователей.
*   **Системы BI (потенциально):** Подключение к ClickHouse для построения кастомных отчетов (например, Tableau, PowerBI).

## 7. Конфигурация (Configuration)

### 7.1. Переменные Окружения
*   `ANALYTICS_API_HTTP_PORT`, `ANALYTICS_API_GRPC_PORT` (если есть gRPC API).
*   `CLICKHOUSE_HOST`, `CLICKHOUSE_PORT`, `CLICKHOUSE_USER`, `CLICKHOUSE_PASSWORD`, `CLICKHOUSE_DATABASE`.
*   `POSTGRES_DSN_ANALYTICS_META`.
*   `S3_ENDPOINT_DATALAKE`, `S3_ACCESS_KEY_DATALAKE`, `S3_SECRET_KEY_DATALAKE`, `S3_BUCKET_DATALAKE`.
*   `KAFKA_BROKERS`.
*   `KAFKA_CONSUMER_GROUP_ANALYTICS`.
*   `SPARK_MASTER_URL` (если используется Spark).
*   `FLINK_JOBMANAGER_RPC_ADDRESS` (если используется Flink).
*   `MLFLOW_TRACKING_URI`.
*   `LOG_LEVEL`.
*   `AUTH_SERVICE_GRPC_ADDR` (для валидации токенов доступа к API).
*   `OTEL_EXPORTER_JAEGER_ENDPOINT`.
*   [Специфичные параметры для пайплайнов обработки данных, ML моделей и другие переменные окружения будут добавлены по мере детализации соответствующих компонентов.]

### 7.2. Файлы Конфигурации (если применимо)
*   `configs/analytics_config.yaml`: Может содержать определения ETL джобов Spark/Flink, конфигурации коннекторов, параметры ML моделей.
*   SQL файлы для создания витрин в ClickHouse.

## 8. Обработка Ошибок (Error Handling)

### 8.1. Общие Принципы
*   Надежная обработка ошибок в пайплайнах приема и обработки данных (DLQ для Kafka, retry механизмы).
*   Мониторинг состояния джобов обработки данных.
*   Информативные ошибки для API запросов.

### 8.2. Распространенные Коды Ошибок (для API)
*   **`METRIC_NOT_FOUND`**
*   **`REPORT_GENERATION_FAILED`**
*   **`INVALID_QUERY_PARAMETERS`**
*   **`DATA_NOT_YET_AVAILABLE`** (для real-time или недавно загруженных данных)
*   (В дополнение к стандартным HTTP ошибкам)

## 9. Безопасность (Security)

### 9.1. Аутентификация
*   JWT/API ключи для доступа к API.
*   Защищенный доступ к хранилищам данных и брокерам сообщений.

### 9.2. Авторизация
*   RBAC для доступа к API и данным (например, разработчики видят только агрегированную статистику по своим играм, администраторы видят все).
*   (Ссылка на `project_roles_and_permissions.md`)

### 9.3. Защита Данных
*   Анонимизация и псевдонимизация PII при обработке и хранении.
*   Соблюдение ФЗ-152.
*   Контроль доступа к Data Lake и DWH.
*   Шифрование чувствительных данных в покое и при передаче.
*   (Ссылка на `project_security_standards.md`)

### 9.4. Управление Секретами
*   Использование Kubernetes Secrets или Vault.

## 10. Развертывание (Deployment)

### 10.1. Инфраструктурные Файлы
*   Dockerfiles для различных компонентов (API сервис, Spark/Flink джобы).
*   Helm-чарты/Kubernetes манифесты.
*   (Ссылка на `project_deployment_standards.md`)

### 10.2. Зависимости при Развертывании
*   ClickHouse, PostgreSQL, S3, Kafka.
*   MLflow (если используется).
*   Доступ к Kafka топикам от всех других сервисов.

### 10.3. CI/CD
*   Пайплайны для сборки API сервисов, джобов обработки данных, ML моделей.
*   Тестирование ETL пайплайнов, валидация данных.
*   (Ссылка на `project_deployment_standards.md`)

## 11. Мониторинг и Логирование (Logging and Monitoring)

### 11.1. Логирование
*   Формат: JSON.
*   Ключевые события: Статус приема данных, ошибки обработки, выполнение ETL джобов, запросы к API.
*   Интеграция: ELK/Loki.
*   (Ссылка на `project_observability_standards.md`)

### 11.2. Мониторинг
*   Метрики (Prometheus):
    *   Объем входящих/обработанных событий Kafka.
    *   Задержка обработки событий.
    *   Состояние и производительность Spark/Flink джобов.
    *   Производительность запросов к ClickHouse.
    *   Ошибки API Analytics Service.
    *   Актуальность данных в витринах.
*   Дашборды (Grafana): Мониторинг состояния пайплайнов данных, производительности DWH, использования ресурсов.
*   Алерты (AlertManager): Сбои в обработке данных, большая задержка данных, недоступность хранилищ.
*   (Ссылка на `project_observability_standards.md`)

### 11.3. Трассировка
*   Интеграция: OpenTelemetry, Jaeger (для API слоя и некоторых критичных частей обработки).
*   (Ссылка на `project_observability_standards.md`)

## 12. Нефункциональные Требования (NFRs)
*   **Производительность**: API запросов к агрегированным данным (P95 < 1 секунды). Скорость обработки событий (зависит от объема, но должна быть близка к real-time для некоторых метрик).
*   **Масштабируемость**: Способность обрабатывать миллиарды событий в день и петабайты данных. Горизонтальное масштабирование компонентов.
*   **Надежность**: Отсутствие потерь данных при приеме. Устойчивость ETL пайплайнов к сбоям.
*   **Актуальность данных (Data Freshness)**: Определить SLO для различных витрин данных (например, real-time, hourly, daily).
*   [Конкретные нефункциональные требования (NFR) для Analytics Service будут определены и добавлены на последующих этапах проектирования.]

## 13. Приложения (Appendices) (Опционально)
*   [Детальные схемы событий, DDL для ClickHouse/PostgreSQL, примеры API запросов, схемы GraphQL и другие приложения будут добавлены в последующих версиях документации или в отдельных специализированных документах.]

---
*Этот документ является отправной точкой и должен регулярно обновляться по мере развития сервиса.*
